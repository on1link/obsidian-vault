  * ## Abstract
    * In this paper, we present a new approach to time series forecasting. Time series data are prevalent in many scientific and engineering disciplines. Time series forecasting is a crucial task in modeling time series data, and is an important area of machine learning. In this work we developed a novel method that employs Transformer-based machine learning models to forecast time  series data. This approach works by leveraging self-attention mechanisms to learn complex patterns and dynamics from time series data. Moreover, it is a generic framework and can be applied to univariate and multivariate time series data, as well as time series embeddings. Using influenza-like illness (ILI) forecasting as a case study, we show that the forecasting results produced by our approach are favorably comparable to the state-of-the-art.

  * ## Primera pasada


  * ## Referencias
    * [[Bahdanau, D.2015 Neural Machine translation by jointly learning to align and translate]]

    * [[Durbin, J.2012 Time Series Analysis by State Space Methods Second Edition]]
    * [[Hochreiter, S.1997 Long short-term memory]]
    * [[Kingma, D.2014 Adam A method for stochastic optimization]]
    * [[Kondo, K.2019 Sequence to sequence with attention for influenza prevalence prediction using google trends]]
    * [[Sugihara, G.1990 Nonlinear forecasting as a way of distinguishing chaos from measurement error in time series]]
    * [[Vaswani, A.2017 Attention is all you need]]
    * [[Zhu, X.2019 Attention-based recurrent neural network for influenza epidemic prediction]]